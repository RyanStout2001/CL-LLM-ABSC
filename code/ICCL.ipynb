{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook performs zero-shot and few-shot learning on the off-the-shelf LLMs, leading to the result shown in Section 5.2.1.\n",
        "\n",
        "This notebook is inspired by: https://github.com/unslothai/unsloth"
      ],
      "metadata": {
        "id": "mUMHiiG5vb8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "1zDZhjnX5xmH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbe7vUKu5n5D"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "unsloth==2025.6.2\n",
        "unsloth_zoo==2025.6.1\n",
        "trl==0.15.2\n",
        "xformers==0.0.29.post3\n",
        "bitsandbytes==0.46.0\n",
        "peft==0.15.2\n",
        "accelerate==1.7.0\n",
        "torch==2.6.0+cu124\n",
        "transformers==4.52.4\n",
        "datasets==3.6.0\n",
        "pandas==2.2.2\n",
        "scikit-learn==1.6.1\n",
        "sentencepiece==0.2.0\n",
        "huggingface-hub\n",
        "hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "import torch.nn.functional as F\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "QlMLSrfrWew-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "G3qDCNrS50Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "8RM55EcBzJi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load and preprocess the XML file into a pandas DataFrame.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load and parse XML file\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Extract data into a list of dictionaries\n",
        "    data = []\n",
        "\n",
        "    # Iterate through the XML structure and extract infomation from the reviews\n",
        "    for review in root.findall('Review'):\n",
        "      review_id = review.get('rid')\n",
        "\n",
        "      for sentence in review.findall('.//sentence'):\n",
        "        text = sentence.find('text').text\n",
        "\n",
        "        # Show nothing rather than 'NULL' in the prompt\n",
        "        for opinion in sentence.findall('.//Opinion'):\n",
        "          aspect = opinion.get('target')\n",
        "          if aspect == 'NULL':\n",
        "            aspect = ''\n",
        "\n",
        "          # Adjust the categories to be more informative for the prompt\n",
        "          category = opinion.get('category').lower().replace('#', ' ').replace('_',' and ')\n",
        "          if category == 'food general':\n",
        "              category = 'food style and options'\n",
        "          elif category == 'service general':\n",
        "              category = 'service'\n",
        "          elif category == 'restaurant general' or category == 'restaurant miscellaneous':\n",
        "              category = 'restaurant'\n",
        "          elif category == 'ambience general':\n",
        "              category = 'ambience'\n",
        "          elif category == 'location general':\n",
        "              category = 'location'\n",
        "\n",
        "          # Represent the aspect as 'term (category entity)'\n",
        "          aspect_term_category = aspect + ' (' + category + ')'\n",
        "\n",
        "          # Format the demonstrations beforehand to easier format the few-shot prompts later on\n",
        "          demonstration = 'Sentence: ' + text + '\\n' + 'Aspect: ' + aspect_term_category + '\\n' + 'Sentiment: ' + opinion.get('polarity') + '\\n'\n",
        "\n",
        "          data.append({\n",
        "              \"sentence\": text,\n",
        "              \"aspect\": aspect,\n",
        "              \"category\": category,\n",
        "              \"aspect_term_category\": aspect_term_category,\n",
        "              \"demonstration\": demonstration,\n",
        "              \"sentiment\": opinion.get('polarity')\n",
        "          })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    y = df['sentiment'].values\n",
        "    label_to_idx = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
        "    df['sentiment_label'] = df['sentiment'].map(label_to_idx)\n",
        "\n",
        "    # Return both the features DataFrame and the sentiment labels\n",
        "    return df, y"
      ],
      "metadata": {
        "id": "Q3WI_E84Hql_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification of zero-shot prompt"
      ],
      "metadata": {
        "id": "VVbrFYLHzVpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_shot_classification(dataset):\n",
        "    \"\"\"\n",
        "    Perform zero-shot classification by predicting the most likely sentiment.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the classes and get their token IDS\n",
        "    classes = [\"negative\", \"neutral\", \"positive\"]\n",
        "    class_token_ids = [tokenizer.encode(c, add_special_tokens=False)[0] for c in classes]\n",
        "\n",
        "    # Create lists to store the predicted classes\n",
        "    pred_sent = []\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    for row in tqdm(dataset):\n",
        "      input = row['zero_shot_prompt']\n",
        "      inputs = tokenizer(input, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "      # Perform inference without computing gradients to save memory\n",
        "      with torch.no_grad():\n",
        "        # This returns the outputs for all input tokens and the next one\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "      # The predicted class should be at the last token (= logit.size(1) -1)\n",
        "      logits = outputs.logits\n",
        "      prediction_position = logits.size(1) - 1\n",
        "\n",
        "      # Retrieve the logits for the classes at the specified position (end of prompt)\n",
        "      logits_for_prediction = logits[:, prediction_position, :]\n",
        "      class_logits = logits_for_prediction[:, class_token_ids]\n",
        "\n",
        "      # Obtain the predicted probabilities class by using the softmax and argmax function respectively\n",
        "      class_probs = F.softmax(class_logits, dim=-1)\n",
        "      probs = class_probs.cpu().detach().float().numpy()\n",
        "      pred_sent.append(classes[np.argmax(probs)])\n",
        "\n",
        "      # To save memory\n",
        "      del inputs, outputs, logits, logits_for_prediction, class_logits, class_probs\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    return pred_sent"
      ],
      "metadata": {
        "id": "H6rERs-eSr6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification for few-shot prompt ()"
      ],
      "metadata": {
        "id": "ZjMyyNBTzTgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot_classification(dataset):\n",
        "    \"\"\"\n",
        "    Perform few-shot classification by predicting the most likely sentiment.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the classes and get their token IDS\n",
        "    classes = [\"negative\", \"neutral\", \"positive\"]\n",
        "    class_token_ids = [tokenizer.encode(c, add_special_tokens=False)[0] for c in classes]\n",
        "\n",
        "    # Create lists to store the predicted classes\n",
        "    pred_sent = []\n",
        "\n",
        "    # Iterate over the dataset\n",
        "    for row in tqdm(dataset):\n",
        "      input = row['few_shot_prompt'] # Few-shot prompt rather than zero-shot prompt\n",
        "      inputs = tokenizer(input, return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "      # Perform inference without computing gradients to save memory\n",
        "      with torch.no_grad():\n",
        "        # This returns the outputs for all input tokens and the next one\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "      # The predicted class should be at the last token (= logit.size(1) -1)\n",
        "      logits = outputs.logits\n",
        "      prediction_position = logits.size(1) - 1\n",
        "\n",
        "      # Retrieve the logits for the classes at the specified position (end of prompt)\n",
        "      logits_for_prediction = logits[:, prediction_position, :]\n",
        "      class_logits = logits_for_prediction[:, class_token_ids]\n",
        "\n",
        "      # Obtain the predicted probabilities class by using the softmax and argmax function respectively\n",
        "      class_probs = F.softmax(class_logits, dim=-1)\n",
        "      probs = class_probs.cpu().detach().float().numpy()\n",
        "      pred_sent.append(classes[np.argmax(probs)])\n",
        "\n",
        "      # To save memory\n",
        "      del inputs, outputs, logits, logits_for_prediction, class_logits, class_probs\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    return pred_sent"
      ],
      "metadata": {
        "id": "5CADD7ngWU3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_few_shot_preds(dataset_train, dataset_test, dem_selection, dem_order, k, order_seed, selection_seed):\n",
        "    \"\"\"\n",
        "    This function allows us to perform few-shot classifation with different input arguments after one another, without having to reinitialize the data.\n",
        "    Without this function, we would get the error that the column few_shot_prompt is already in the dataset if we tried to format the few-shot prompts again for a different configuration.\n",
        "    \"\"\"\n",
        "\n",
        "    few_shot_dict = format_few_shot_prompts(dataset_train, dataset_test, dem_selection, dem_order, k, order_seed, selection_seed)\n",
        "    if \"few_shot_prompt\" in dataset_test.column_names:\n",
        "        dataset_test = dataset_test.remove_columns(\"few_shot_prompt\")\n",
        "    dataset_test = dataset_test.add_column(\n",
        "        \"few_shot_prompt\",\n",
        "        few_shot_dict[\"few_shot_prompt\"]\n",
        "    )\n",
        "\n",
        "    y_pred_few = few_shot_classification(dataset_test)\n",
        "    return y_pred_few"
      ],
      "metadata": {
        "id": "wVckiyNFSES1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts"
      ],
      "metadata": {
        "id": "qTplR-3B9Eqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load either the prompts for the Mistral model, or the prompts for the Llama and Gemma model"
      ],
      "metadata": {
        "id": "nZid5AoVv9vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mistral"
      ],
      "metadata": {
        "id": "IAPh8h379KTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"\"\"Classify the sentiment expressed towards the given aspect within the provided sentence as 'negative', 'neutral' or 'positive'.\n",
        "\n",
        "### Sentence:\n",
        "{}\n",
        "\n",
        "### Aspect:\n",
        "{}\n",
        "\n",
        "### Sentiment:\n",
        " \"\"\"\n",
        "\n",
        "def format_zero_shot_prompts(data):\n",
        "    \"\"\"\n",
        "    This function formats the prompts for zero-shot classification.\n",
        "    \"\"\"\n",
        "\n",
        "    sentences      = data[\"sentence\"]\n",
        "    aspects        = data[\"aspect_term_category\"]\n",
        "    prompts = []\n",
        "\n",
        "    # Format the zero-shot prompt for every test instance\n",
        "    for sentence, aspect in zip(sentences, aspects):\n",
        "      prompt = zero_shot_prompt.format(sentence, aspect)\n",
        "      prompts.append(prompt)\n",
        "\n",
        "    return { \"zero_shot_prompt\" : prompts }"
      ],
      "metadata": {
        "id": "rJt7TEud8I1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"Classify the sentiment expressed towards the given aspect within the provided sentence as 'negative', 'neutral' or 'positive'.\n",
        "\n",
        "### Examples:\n",
        "{}\n",
        "### Sentence:\n",
        "{}\n",
        "\n",
        "### Aspect:\n",
        "{}\n",
        "\n",
        "Sentiment:\n",
        " \"\"\"\n",
        "\n",
        "def format_examples(subset, dem_order, order_seed):\n",
        "    \"\"\"\n",
        "    This function orders the demonstrations shown within the prompt\n",
        "    \"\"\"\n",
        "\n",
        "    # Order the demonstrations, given the ordering method\n",
        "    if dem_order == 'sso':\n",
        "      ordered_set = subset\n",
        "    elif dem_order == 'ro':\n",
        "      ordered_set = subset.shuffle(seed=order_seed)\n",
        "    elif dem_order == 'swn':\n",
        "      ordered_set = subset.sort('swn')\n",
        "    elif dem_order == 'sl':\n",
        "      ordered_set = subset.sort('sl')\n",
        "    elif dem_order == 'ce':\n",
        "      ordered_set = subset.sort('ce')\n",
        "\n",
        "    # Print the ordered demonstrations below each other\n",
        "    k_examples = ''\n",
        "    for row in ordered_set:\n",
        "      k_examples += row['demonstration']\n",
        "      k_examples += '\\n'\n",
        "\n",
        "    return k_examples\n",
        "\n",
        "\n",
        "def format_few_shot_prompts(train_data, test_data, dem_selection, dem_order, k, order_seed, selection_seed):\n",
        "    \"\"\"\n",
        "    This function formats the prompts for few-shot classification.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize all the elements needed to form the prompts\n",
        "    np.random.seed(selection_seed)\n",
        "    sentences      = test_data[\"sentence\"]\n",
        "    aspects        = test_data[\"aspect_term_category\"]\n",
        "    indices       = test_data[\"original_indices\"]\n",
        "    prompts = []\n",
        "\n",
        "    # For every test instance\n",
        "    for sentence, aspect, index in zip(sentences, aspects, indices):\n",
        "\n",
        "      # Select the demonstrations\n",
        "      if dem_selection == 'rs':\n",
        "        k_indices = np.random.choice(len(train_data), size=k, replace=False)\n",
        "      elif dem_selection == 'hkate':\n",
        "        k_indices = test_data['HKATE_indices'][index][0:k]\n",
        "        if dem_order == 'sso':\n",
        "          k_indices = k_indices[::-1]\n",
        "      elif dem_selection == 'kate':\n",
        "        k_indices = test_data['KATE_indices'][index][0:k]\n",
        "        if dem_order == 'sso':\n",
        "          k_indices = k_indices[::-1]\n",
        "\n",
        "      # Order and format the demonstrations\n",
        "      k_examples = format_examples(train_data.select(k_indices), dem_order, order_seed)\n",
        "\n",
        "      # Format the few-shot prompt\n",
        "      prompt = few_shot_prompt.format(k_examples, sentence, aspect)\n",
        "      prompts.append(prompt)\n",
        "\n",
        "    return { \"few_shot_prompt\" : prompts }"
      ],
      "metadata": {
        "id": "MaM5p_CDyn9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama and Gemma"
      ],
      "metadata": {
        "id": "QC4ctmyW9Lxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt = \"\"\"Classify the sentiment expressed towards the given aspect within the provided sentence as 'negative', 'neutral' or 'positive'.\n",
        "\n",
        "### Sentence:\n",
        "{}\n",
        "\n",
        "### Aspect:\n",
        "{}\n",
        "\n",
        "### Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "def format_zero_shot_prompts(data):\n",
        "    \"\"\"\n",
        "    This function formats the prompts for zero-shot classification.\n",
        "    \"\"\"\n",
        "\n",
        "    sentences      = data[\"sentence\"]\n",
        "    aspects        = data[\"aspect_term_category\"]\n",
        "    prompts = []\n",
        "\n",
        "    # Format the zero-shot prompt for every test instance\n",
        "    for sentence, aspect in zip(sentences, aspects):\n",
        "      prompt = zero_shot_prompt.format(sentence, aspect)\n",
        "      prompts.append(prompt)\n",
        "\n",
        "    return { \"zero_shot_prompt\" : prompts }"
      ],
      "metadata": {
        "id": "ZM6_FPSW9HFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = \"\"\"Classify the sentiment expressed towards the given aspect within the provided sentence as 'negative', 'neutral' or 'positive'.\n",
        "\n",
        "### Examples:\n",
        "{}\n",
        "### Sentence:\n",
        "{}\n",
        "\n",
        "### Aspect:\n",
        "{}\n",
        "\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "\n",
        "def format_examples(subset, dem_order, order_seed):\n",
        "    \"\"\"\n",
        "    This function orders the demonstrations shown within the prompt\n",
        "    \"\"\"\n",
        "\n",
        "    # Order the demonstrations, given the ordering method\n",
        "    if dem_order == 'sso':\n",
        "      ordered_set = subset\n",
        "    elif dem_order == 'ro':\n",
        "      ordered_set = subset.shuffle(seed=order_seed)\n",
        "    elif dem_order == 'swn':\n",
        "      ordered_set = subset.sort('swn')\n",
        "    elif dem_order == 'sl':\n",
        "      ordered_set = subset.sort('sl')\n",
        "    elif dem_order == 'ce':\n",
        "      ordered_set = subset.sort('ce')\n",
        "\n",
        "    # Print the ordered demonstrations below each other\n",
        "    k_examples = ''\n",
        "    for row in ordered_set:\n",
        "      k_examples += row['demonstration']\n",
        "      k_examples += '\\n'\n",
        "\n",
        "    return k_examples\n",
        "\n",
        "\n",
        "def format_few_shot_prompts(train_data, test_data, dem_selection, dem_order, k, order_seed, selection_seed):\n",
        "    \"\"\"\n",
        "    This function formats the prompts for few-shot classification.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize all the elements needed to form the prompts\n",
        "    np.random.seed(selection_seed)\n",
        "    sentences      = test_data[\"sentence\"]\n",
        "    aspects        = test_data[\"aspect_term_category\"]\n",
        "    indices       = test_data[\"original_indices\"]\n",
        "    prompts = []\n",
        "\n",
        "    # For every test instance\n",
        "    for sentence, aspect, index in zip(sentences, aspects, indices):\n",
        "\n",
        "      # Select the demonstrations\n",
        "      if dem_selection == 'rs':\n",
        "        k_indices = np.random.choice(len(train_data), size=k, replace=False)\n",
        "      elif dem_selection == 'hkate':\n",
        "        k_indices = test_data['HKATE_indices'][index][0:k]\n",
        "        if dem_order == 'sso':\n",
        "          k_indices = k_indices[::-1]\n",
        "      elif dem_selection == 'kate':\n",
        "        k_indices = test_data['KATE_indices'][index][0:k]\n",
        "        if dem_order == 'sso':\n",
        "          k_indices = k_indices[::-1]\n",
        "\n",
        "      # Order and format the demonstrations\n",
        "      k_examples = format_examples(train_data.select(k_indices), dem_order, order_seed)\n",
        "\n",
        "      # Format the few-shot prompt\n",
        "      prompt = few_shot_prompt.format(k_examples, sentence, aspect)\n",
        "      prompts.append(prompt)\n",
        "\n",
        "    return { \"few_shot_prompt\" : prompts }"
      ],
      "metadata": {
        "id": "_TF85oOg9HFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "q9PtYGLX9Zka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this code, first upload the files:\n",
        "\n",
        "*   '201x_Restaurants_Train.xml'\n",
        "*   '201x_Restaurants_Test.xml'\n",
        "*   'top_k_indices_201x.csv'\n",
        "*   'swn_complexity_scores_201x.csv'\n",
        "*   'sentence_lengths_201x.csv'\n",
        "*   'ce_model_201x.csv'\n",
        "\n",
        "with model being either mistral, llama or gemma and 201x being either 2015 or 2016.\n",
        "\n",
        "NOTE: Make sure to only (or at last) run the prompts corresponding to the model you are using! Otherwise, inconsistency in sentiment label tokenization will mess up the results!\n",
        "\n",
        "Once you have completed all the runs for a model, reconnect the runtime before moving on to another LLM."
      ],
      "metadata": {
        "id": "pSoC9qD5ACIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model"
      ],
      "metadata": {
        "id": "-SuKckeS9a_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose and load a model"
      ],
      "metadata": {
        "id": "kqGFYcxEAgHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_name = \"unsloth/mistral-7b-v0.3-bnb-4bit\"\n",
        "model_name = \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\"\n",
        "#model_name = \"unsloth/gemma-2-9b-bnb-4bit\""
      ],
      "metadata": {
        "id": "oWg0JaguwA2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 1024\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,\n",
        "    max_seq_length = 1024,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")"
      ],
      "metadata": {
        "id": "5m13dli5aBC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "fIeqdA3C92oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load either the 2015 or 2016 data"
      ],
      "metadata": {
        "id": "G__SQs47zLOk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh-rYhT9a0ZC"
      },
      "source": [
        "### 2015"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHZ1bAvCa64v"
      },
      "outputs": [],
      "source": [
        "# Load train data\n",
        "df_train, y_train = load_data('2015_Restaurants_Train.xml')\n",
        "df_train['original_indices'] = df_train.index\n",
        "df_train['sl'] = pd.read_csv('sentence_lengths_2015.csv')\n",
        "df_train['swn'] = pd.read_csv('swn_complexity_scores_2015.csv')\n",
        "if model_name == \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_llama_2015.csv')\n",
        "elif model_name == \"unsloth/mistral-7b-v0.3-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_mistral_2015.csv')\n",
        "elif model_name == \"unsloth/gemma-2-9b-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_gemma_2015.csv')\n",
        "\n",
        "# Load test data\n",
        "df_test, y_test = load_data('2015_Restaurants_Test.xml')\n",
        "df_test['original_indices'] = df_test.index\n",
        "df_test['KATE_indices'] = pd.read_csv('top_k_indices_2015.csv')\n",
        "df_test['KATE_indices'] = df_test['KATE_indices'].apply(ast.literal_eval)\n",
        "\n",
        "# Convert to huggingface Datasets\n",
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_test = Dataset.from_pandas(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4G9twpsFQ8d"
      },
      "source": [
        "### 2016"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRl5gVv1FQr7"
      },
      "outputs": [],
      "source": [
        "# Load train data\n",
        "df_train, y_train = load_data('2016_Restaurants_Train.xml')\n",
        "df_train['original_indices'] = df_train.index\n",
        "df_train['sl'] = pd.read_csv('sentence_lengths_2016.csv')\n",
        "df_train['swn'] = pd.read_csv('swn_complexity_scores_2016.csv')\n",
        "if model_name == \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_llama_2016.csv')\n",
        "elif model_name == \"unsloth/mistral-7b-v0.3-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_mistral_2016.csv')\n",
        "elif model_name == \"unsloth/gemma-2-9b-bnb-4bit\":\n",
        "  df_train['ce'] = pd.read_csv('ce_gemma_2016.csv')\n",
        "\n",
        "# Load test data\n",
        "df_test, y_test = load_data('2016_Restaurants_Test.xml')\n",
        "df_test['original_indices'] = df_test.index\n",
        "df_test['KATE_indices'] = pd.read_csv('top_k_indices_2016.csv')\n",
        "df_test['KATE_indices'] = df_test['KATE_indices'].apply(ast.literal_eval)\n",
        "\n",
        "# Convert to huggingface Datasets\n",
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_test = Dataset.from_pandas(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Learning"
      ],
      "metadata": {
        "id": "neuo870lbVV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform zero-shot learning, print the evaluation metrics, and save the predictions"
      ],
      "metadata": {
        "id": "oggC9c2XArGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = dataset_test.map(format_zero_shot_prompts, batched = True,)\n",
        "y_pred_zero = zero_shot_classification(dataset_test)\n",
        "print('\\n zero-shot: \\n', classification_report(y_test, y_pred_zero, digits = 4))\n",
        "pd.Series(y_pred_zero).to_csv('llama2016_zero.csv', index=False)"
      ],
      "metadata": {
        "id": "85tW7nN_bMuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot Learning"
      ],
      "metadata": {
        "id": "LY-aNHXBhLd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform few-shot learning, print the evaluation metrics, and save the predictions for all configurations.\n",
        "\n",
        "Here k are the number of demonstrations and the abbreviations are defined as:\n",
        "\n",
        "*   rs = Random Selection\n",
        "*   kate = K-nn Augmented in-conText Example selection\n",
        "*   hkate = Hierachical KATE\n",
        "*   ro = Random Ordering\n",
        "*   sso = Semantic Similarity Ordering\n",
        "*   sl = Sentence Length\n",
        "*   swn = SentiWordNet\n",
        "*   ce = Cross-Entropy\n",
        "\n"
      ],
      "metadata": {
        "id": "Hnal6zAnF2Og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k = 5, RS"
      ],
      "metadata": {
        "id": "ndsxKGB6ZDbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_ro1 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot rs ro 1: \\n', classification_report(y_test, y_pred_k5_rs_ro1, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_ro1).to_csv('llama2016_k5_rs_ro1.csv', index=False)"
      ],
      "metadata": {
        "id": "KyArLrIJVUql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_ro2 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 5, order_seed = 2, selection_seed = 1)\n",
        "print('\\n 5-shot rs ro 2: \\n', classification_report(y_test, y_pred_k5_rs_ro2, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_ro2).to_csv('llama2016_k5_rs_ro2.csv', index=False)"
      ],
      "metadata": {
        "id": "d1YFP7SYDnC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_ro3 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 5, order_seed = 3, selection_seed = 1)\n",
        "print('\\n 5-shot rs ro 3: \\n', classification_report(y_test, y_pred_k5_rs_ro3, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_ro3).to_csv('llama2016_k5_rs_ro3.csv', index=False)"
      ],
      "metadata": {
        "id": "1Hc1j7uYDrFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_sl = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'sl', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot rs sl: \\n', classification_report(y_test, y_pred_k5_rs_sl, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_sl).to_csv('llama2016_k5_rs_sl.csv', index=False)"
      ],
      "metadata": {
        "id": "pMMMscGRDvXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_swn = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'swn', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot rs swn: \\n', classification_report(y_test, y_pred_k5_rs_swn, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_swn).to_csv('llama2016_k5_rs_swn.csv', index=False)"
      ],
      "metadata": {
        "id": "FEosHnFHDypv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_rs_ce = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ce', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot rs ce: \\n', classification_report(y_test, y_pred_k5_rs_ce, digits = 4))\n",
        "pd.Series(y_pred_k5_rs_ce).to_csv('llama2016_k5_rs_ce.csv', index=False)"
      ],
      "metadata": {
        "id": "-DXnKWW9DzFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K = 5, KATE"
      ],
      "metadata": {
        "id": "JqtTXfyQEclG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_ro1 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot kate ro 1: \\n', classification_report(y_test, y_pred_k5_kate_ro1, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_ro1).to_csv('llama2016_k5_kate_ro1.csv', index=False)"
      ],
      "metadata": {
        "id": "E-M4V2FlEclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_ro2 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 5, order_seed = 2, selection_seed = 1)\n",
        "print('\\n 5-shot kate ro 2: \\n', classification_report(y_test, y_pred_k5_kate_ro2, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_ro2).to_csv('llama2016_k5_kate_ro2.csv', index=False)"
      ],
      "metadata": {
        "id": "DNoEbxQqEclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_ro3 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 5, order_seed = 3, selection_seed = 1)\n",
        "print('\\n 5-shot kate ro 3: \\n', classification_report(y_test, y_pred_k5_kate_ro3, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_ro3).to_csv('llama2016_k5_kate_ro3.csv', index=False)"
      ],
      "metadata": {
        "id": "r00zZ7bWEclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_sso = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'sso', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot kate sso: \\n', classification_report(y_test, y_pred_k5_kate_sso, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_sso).to_csv('llama2016_k5_kate_sso.csv', index=False)"
      ],
      "metadata": {
        "id": "FQRZs4qSEclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_sl = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'sl', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot kate sl: \\n', classification_report(y_test, y_pred_k5_kate_sl, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_sl).to_csv('llama2016_k5_kate_sl.csv', index=False)"
      ],
      "metadata": {
        "id": "wJ4XY0uiEclO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_swn = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'swn', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot kate swn: \\n', classification_report(y_test, y_pred_k5_kate_swn, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_swn).to_csv('llama2016_k5_kate_swn.csv', index=False)"
      ],
      "metadata": {
        "id": "qt2sN4LYEclP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k5_kate_ce = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ce', k = 5, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 5-shot kate ce: \\n', classification_report(y_test, y_pred_k5_kate_ce, digits = 4))\n",
        "pd.Series(y_pred_k5_kate_ce).to_csv('llama2016_k5_kate_ce.csv', index=False)"
      ],
      "metadata": {
        "id": "7IkyEnzTEclP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K = 10, RS"
      ],
      "metadata": {
        "id": "Bs_HKtGHZFuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_ro1 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot rs ro 1: \\n', classification_report(y_test, y_pred_k10_rs_ro1, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_ro1).to_csv('llama2016_k10_rs_ro1.csv', index=False)"
      ],
      "metadata": {
        "id": "3QympYjAIMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_ro2 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 10, order_seed = 2, selection_seed = 1)\n",
        "print('\\n 10-shot rs ro 2: \\n', classification_report(y_test, y_pred_k10_rs_ro2, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_ro2).to_csv('llama2016_k10_rs_ro2.csv', index=False)"
      ],
      "metadata": {
        "id": "sf6FoPd5IMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_ro3 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ro', k = 10, order_seed = 3, selection_seed = 1)\n",
        "print('\\n 10-shot rs ro 3: \\n', classification_report(y_test, y_pred_k10_rs_ro3, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_ro3).to_csv('llama2016_k10_rs_ro3.csv', index=False)"
      ],
      "metadata": {
        "id": "Xol4k6NvIMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_sl = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'sl', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot rs sl: \\n', classification_report(y_test, y_pred_k10_rs_sl, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_sl).to_csv('llama2016_k10_rs_sl.csv', index=False)"
      ],
      "metadata": {
        "id": "0rdeR90CIMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_swn = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'swn', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot rs swn: \\n', classification_report(y_test, y_pred_k10_rs_swn, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_swn).to_csv('llama2016_k10_rs_swn.csv', index=False)"
      ],
      "metadata": {
        "id": "X9atDrjXIMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_rs_ce = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='rs', dem_order = 'ce', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot rs ce: \\n', classification_report(y_test, y_pred_k10_rs_ce, digits = 4))\n",
        "pd.Series(y_pred_k10_rs_ce).to_csv('llama2016_k10_rs_ce.csv', index=False)"
      ],
      "metadata": {
        "id": "WkqTDvecIMoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K = 10, KATE"
      ],
      "metadata": {
        "id": "BurLXx4JFBcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_ro1 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot kate ro 1: \\n', classification_report(y_test, y_pred_k10_kate_ro1, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_ro1).to_csv('llama2016_k10_kate_ro1.csv', index=False)"
      ],
      "metadata": {
        "id": "qN9iyIznFBco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_ro2 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 10, order_seed = 2, selection_seed = 1)\n",
        "print('\\n 10-shot kate ro 2: \\n', classification_report(y_test, y_pred_k10_kate_ro2, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_ro2).to_csv('llama2016_k10_kate_ro2.csv', index=False)"
      ],
      "metadata": {
        "id": "YR3YpYGeFBcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_ro3 = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ro', k = 10, order_seed = 3, selection_seed = 1)\n",
        "print('\\n 10-shot kate ro 3: \\n', classification_report(y_test, y_pred_k10_kate_ro3, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_ro3).to_csv('llama2016_k10_kate_ro3.csv', index=False)"
      ],
      "metadata": {
        "id": "Vcm6N05CFBcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_sso = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'sso', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot kate sso: \\n', classification_report(y_test, y_pred_k10_kate_sso, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_sso).to_csv('llama2016_k10_kate_sso.csv', index=False)"
      ],
      "metadata": {
        "id": "8tUoCGcTFBcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_sl = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'sl', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot kate sl: \\n', classification_report(y_test, y_pred_k10_kate_sl, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_sl).to_csv('llama2016_k10_kate_sl.csv', index=False)"
      ],
      "metadata": {
        "id": "8XVJVPvBFBcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_swn = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'swn', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot kate swn: \\n', classification_report(y_test, y_pred_k10_kate_swn, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_swn).to_csv('llama2016_k10_kate_swn.csv', index=False)"
      ],
      "metadata": {
        "id": "XPhZ04ldFBcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_k10_kate_ce = run_few_shot_preds(dataset_train, dataset_test, dem_selection ='kate', dem_order = 'ce', k = 10, order_seed = 1, selection_seed = 1)\n",
        "print('\\n 10-shot kate ce: \\n', classification_report(y_test, y_pred_k10_kate_ce, digits = 4))\n",
        "pd.Series(y_pred_k10_kate_ce).to_csv('llama2016_k10_kate_ce.csv', index=False)"
      ],
      "metadata": {
        "id": "-ftdNVdwFBcq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}